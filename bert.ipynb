{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pprint \n",
    "import re\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_data = pd.read_csv('misc/processed_music_info.csv')\n",
    "track_lyrics = pd.read_csv('misc/track_lyrics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_lyrics.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_ids_exist = track_data['track_id'].isin(track_lyrics['track_id'])\n",
    "all_track_ids_exist = track_ids_exist.all()\n",
    "if not all_track_ids_exist:\n",
    "\tprint('Some track ids do not exist in track_lyrics')\n",
    "\tprint(track_data[~track_ids_exist])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    if text == \"This song is instrumental.\":\n",
    "        return \"\"\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = re.sub(r'[^A-Za-z0-9 ]+', ' ', text)\n",
    "    text = text.replace(\"|||\", \" \")\n",
    "    return text.strip()\n",
    "\n",
    "track_lyrics['lyrics'] = track_lyrics['lyrics'].apply(clean_text)\n",
    "track_data.set_index('track_id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in track_lyrics.iterrows():\n",
    "    track_id = row['track_id']\n",
    "    if track_id in track_data.index:\n",
    "        track_data_row = track_data.loc[track_id]\n",
    "        new_lyrics = f\"song lyrics: {row['lyrics']}, song title: {track_data_row['name']}, song artist: {track_data_row['artist']}, song genres: {track_data_row['tags']}\"\n",
    "        track_lyrics.at[idx, 'lyrics'] = new_lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_lyrics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sentence_transformers import SentenceTransformer, models\n",
    "from torch import nn\n",
    "\n",
    "saved_transformer_path = 'misc/sentence_transformer'\n",
    "saved_embeddings_path = 'misc/lyrics_embeddings.npy'\n",
    "saved_embeddings_3d_path = 'misc/lyrics_embeddings_3d.npy'\n",
    "\n",
    "if os.path.exists(saved_transformer_path):\n",
    "\tmodel = SentenceTransformer(saved_transformer_path)\n",
    "else:\n",
    "\tword_embedding_model = models.Transformer(\"bert-base-uncased\", max_seq_length=150)\n",
    "\tpooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension())\n",
    "\tdense_model = models.Dense(\n",
    "\t\tin_features=pooling_model.get_sentence_embedding_dimension(),\n",
    "\t\tout_features=150,\n",
    "\t\tactivation_function=nn.Tanh(),\n",
    "\t)\n",
    "\tmodel = SentenceTransformer(modules=[word_embedding_model, pooling_model, dense_model])\n",
    "\t\n",
    "\tmodel.save(saved_transformer_path)\n",
    "\n",
    "model = SentenceTransformer.load('misc/sentence_transformer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(saved_embeddings_path):\n",
    "\tlyrics_embeddings = np.load(saved_embeddings_path)\n",
    "else:\n",
    "\tlyrics_embeddings = model.encode(track_lyrics['lyrics'], show_progress_bar=True)\n",
    "\tnp.save('misc/lyrics_embeddings.npy', lyrics_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyrics_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint.pprint(lyrics_embeddings[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(saved_embeddings_3d_path):\n",
    "\tembeddings_3d = np.load(saved_embeddings_3d_path)\n",
    "else:\n",
    "\ttsne = TSNE(n_components=3, random_state=42)\n",
    "\tembeddings_3d = tsne.fit_transform(lyrics_embeddings)\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter3d(\n",
    "    x=embeddings_3d[:, 0],\n",
    "    y=embeddings_3d[:, 1],\n",
    "    z=embeddings_3d[:, 2],\n",
    "\ttext=track_data['tags'],\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        size=2,\n",
    "        color=embeddings_3d[:, 2], \n",
    "        colorscale='Viridis',\n",
    "        opacity=0.8\n",
    "    )\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    scene=dict(\n",
    "        xaxis=dict(title='x'),\n",
    "        yaxis=dict(title='y'),\n",
    "        zaxis=dict(title='z')\n",
    "    ),\n",
    "\twidth=1000,\n",
    "    height=800\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('misc/lyrics_embeddings_3d.npy', embeddings_3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_index = np.random.randint(0, len(embeddings_3d))\n",
    "\n",
    "nn_model = NearestNeighbors(n_neighbors=6)\n",
    "nn_model.fit(embeddings_3d)\n",
    "\n",
    "distances, indices = nn_model.kneighbors(embeddings_3d[random_index].reshape(1, -1))\n",
    "\n",
    "nearest_indices = indices[0][1:]\n",
    "nearest_indices = np.insert(nearest_indices, 0, random_index)\n",
    "track_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(\"target song:\", random_index)\n",
    "track_data.iloc[nearest_indices][['name', 'artist', 'year', 'loudness', 'danceability', 'liveness', 'tags']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
